<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to carry out reproductions and replications in the social, cognitive, and behavioral sciences">

<title>6&nbsp; Execution of Replications – Handbook for Reproduction and Replication Studies</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./discussion.html" rel="next">
<link href="./execution_reproductions.html" rel="prev">
<link href="./images/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-4ec7246897d00c06100498262f8bc0a3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./choosing_study.html">The Replication Process</a></li><li class="breadcrumb-item"><a href="./execution_replications.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Execution of Replications</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Handbook for Reproduction and Replication Studies</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/forrtproject/replication_guide/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Handbook-for-Reproduction-and-Replication-Studies.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Background</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding Replications and Reproductions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">The Replication Process</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./choosing_study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Choosing the Target Study</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./planning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Planning and Conducting Reproductions and Replications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./execution_reproductions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Execution of Reproductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./execution_replications.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Execution of Replications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics and Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./publishing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Communicating and Publishing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./field_specific_mri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Field-Specific Replication Challenges: An example from MRI research</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Conclusion and Checklist</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Author Contributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix_templates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Email templates</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#preregistration-and-registered-replication-reports" id="toc-preregistration-and-registered-replication-reports" class="nav-link active" data-scroll-target="#preregistration-and-registered-replication-reports"><span class="header-section-number">6.1</span> Preregistration and Registered (Replication) Reports</a></li>
  <li><a href="#sample-size-determination" id="toc-sample-size-determination" class="nav-link" data-scroll-target="#sample-size-determination"><span class="header-section-number">6.2</span> Sample Size Determination</a>
  <ul class="collapse">
  <li><a href="#small-telescopes-approach" id="toc-small-telescopes-approach" class="nav-link" data-scroll-target="#small-telescopes-approach"><span class="header-section-number">6.2.1</span> Small Telescopes Approach</a></li>
  <li><a href="#equivalence-testing" id="toc-equivalence-testing" class="nav-link" data-scroll-target="#equivalence-testing"><span class="header-section-number">6.2.2</span> Equivalence Testing</a></li>
  <li><a href="#bayesian-approach" id="toc-bayesian-approach" class="nav-link" data-scroll-target="#bayesian-approach"><span class="header-section-number">6.2.3</span> Bayesian Approach</a></li>
  <li><a href="#meta-analytical-estimates" id="toc-meta-analytical-estimates" class="nav-link" data-scroll-target="#meta-analytical-estimates"><span class="header-section-number">6.2.4</span> Meta-Analytical Estimates</a></li>
  <li><a href="#multilab-replications" id="toc-multilab-replications" class="nav-link" data-scroll-target="#multilab-replications"><span class="header-section-number">6.2.5</span> Multilab Replications</a></li>
  </ul></li>
  <li><a href="#changes-in-the-methods" id="toc-changes-in-the-methods" class="nav-link" data-scroll-target="#changes-in-the-methods"><span class="header-section-number">6.3</span> Changes in the Methods</a></li>
  <li><a href="#piloting" id="toc-piloting" class="nav-link" data-scroll-target="#piloting"><span class="header-section-number">6.4</span> Piloting</a>
  <ul class="collapse">
  <li><a href="#collaborating-and-consulting-with-the-original-authors" id="toc-collaborating-and-consulting-with-the-original-authors" class="nav-link" data-scroll-target="#collaborating-and-consulting-with-the-original-authors"><span class="header-section-number">6.4.1</span> Collaborating and Consulting with the Original Authors</a></li>
  </ul></li>
  <li><a href="#adversarial-collaborations" id="toc-adversarial-collaborations" class="nav-link" data-scroll-target="#adversarial-collaborations"><span class="header-section-number">6.5</span> Adversarial Collaborations</a></li>
  <li><a href="#analysis" id="toc-analysis" class="nav-link" data-scroll-target="#analysis"><span class="header-section-number">6.6</span> Analysis</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./choosing_study.html">The Replication Process</a></li><li class="breadcrumb-item"><a href="./execution_replications.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Execution of Replications</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Execution of Replications</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preregistration-and-registered-replication-reports" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="preregistration-and-registered-replication-reports"><span class="header-section-number">6.1</span> Preregistration and Registered (Replication) Reports</h2>
<p>Due to the replications being met with skepticism, we encourage researchers to adhere to the highest standards of openness and transparency. This includes preregistering the replication including the analysis plan (ideally with an analysis code that was tested beforehand using data from test runs or simulations), and criteria for the results to distinguish between a replication success and failure. A preregistration without an analysis plan provides no safeguard against <em>p</em>-hacking <span class="citation" data-cites="BrodeurEtAl2024a">(<a href="references.html#ref-BrodeurEtAl2024a" role="doc-biblioref">Brodeur et al., 2024</a>)</span>. Beware that these criteria can be structured sequentially. For example, if there is a manipulation check, it can be defined that it has to work for the replicability to actually be evaluated. Boyce et al. <span class="citation" data-cites="BoyceEtAl2024">(<a href="references.html#ref-BoyceEtAl2024" role="doc-biblioref">2024</a>)</span> also found that repeating unsuccessful replications did not change the outcomes unless obvious weaknesses were fixed.</p>
<p>There is a specific preregistration template by Brandt et al. <span class="citation" data-cites="BrandtEtAl2014">(<a href="references.html#ref-BrandtEtAl2014" role="doc-biblioref">2014</a>)</span> but it may not fit the structure of some studies beyond social psychology (e.g., personality science or cognitive psychology; for a list of preregistration templates see <a href="https://osf.io/7xrn9">https://osf.io/7xrn9</a> and <a href="https://osf.io/zab38/wiki/home">https://osf.io/zab38/wiki/home</a>). To facilitate publication of the replication, we furthermore encourage submitting it as a Registered Report. A rejection due to the results is not possible at this point. A list of journals offering Registered Reports (irrespective of replications) is <a href="https://docs.google.com/spreadsheets/d/1D4_k-8C_UENTRtbPzXfhjEyu3BfLxdOsn9j-otrO870/edit#gid=0">available online</a>.</p>
<p>A special review platform for Registered Reports is <em>Peer Community in Registered Reports</em> (PCI-RR; <a href="https://rr.peercommunityin.org">https://rr.peercommunityin.org</a>) where a community reviews pre-prints. Once accepted by PCI-RR, authors can decide to publish their paper in participating journals (PCI friendly journals) without another editorial round.</p>
<p>Finally, replication researchers need to deal with deviations from their preregistration in a transparent way. In principle, there is nothing wrong with deviating from what one had planned but most importantly, all changes should be listed, discussed, and it should be made transparent how the changes affected the results (for recommendations on changes and documentation, see <span class="citation" data-cites="Lakens2024">Lakens (<a href="references.html#ref-Lakens2024" role="doc-biblioref">2024</a>)</span>, and <span class="citation" data-cites="WillrothAtherton2024">Willroth &amp; Atherton (<a href="references.html#ref-WillrothAtherton2024" role="doc-biblioref">2024</a>)</span>. If changes are noticed during the data collection, many platforms also allow the upload of amendments with preserved version history.</p>
</section>
<section id="sample-size-determination" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="sample-size-determination"><span class="header-section-number">6.2</span> Sample Size Determination</h2>
<p>For replication studies, power analyses or other types of sample size justification can be simpler than for studies testing entirely new hypotheses because there already is a study that did what one is planning, with a result that one can refer to. However, we advise against simply using the original study’s sample size. While the maxim for most decisions is “stay as close as possible to the original study”, sample sizes of replication studies usually need to be larger. To be informative, replication failure should provide evidence <em>for </em>a null hypothesis or a substantially smaller effect size, which requires a larger sample. While a general tutorial for sample size justification is provided by Lakens <span class="citation" data-cites="Lakens2022b">(<a href="references.html#ref-Lakens2022b" role="doc-biblioref">2022</a>)</span>, we briefly present approaches that are fit for replication studies.</p>
<p>As a pair of original and replication studies is usually concerned with multiple effect sizes (e.g., for different scales/items/groups/hypotheses), their number and individual power need to be considered carefully. If the interpretation will rely on the significance of <em>all </em>effect sizes, the total power will be smaller than the power for each individual test. To get along with limited resources, researchers may choose one single effect size and argue that it is central, or clearly specify other methods for aggregation across results (e.g., testing multivariate models).</p>
<section id="small-telescopes-approach" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="small-telescopes-approach"><span class="header-section-number">6.2.1</span> Small Telescopes Approach</h3>
<p>The idea behind the small telescopes approach <span class="citation" data-cites="Simonsohn2015">(<a href="references.html#ref-Simonsohn2015" role="doc-biblioref">Simonsohn, 2015</a>)</span> is that a replication study should be precise but how far this precision exceeds the original study should be limited. Specifically, the replication study should be able to detect an effect size for which the original study had insufficient power (usually 33%). If that effect size can be ruled out, the original study can be treated as uninformative, as with such low power, the result becomes more likely to have been a false positive.</p>
<p>This approach is based on the notion that replications should assess the evidentiary value of the original study, and that the ‘burden of proof’ shifts back to proponents of a hypothesis if their evidence is shown to be very weak. It is particularly appropriate when original studies are very imprecise. In that case, a replication that finds a much smaller effect may well still be compatible with the (wide) confidence interval of the original study, and it might be impossible to reject the original claim on that basis.</p>
<p>As an example, <span class="citation" data-cites="SchultzeEtAl2018">Schultze et al. (<a href="references.html#ref-SchultzeEtAl2018" role="doc-biblioref">2018, Figure 4</a>)</span> found an effect in three studies with an average effect size of <em>r</em> = -.11, 95% CI [-.22, -.01].</p>
<p>If we wanted to achieve high power to rule out an effect of -.01, and thus show that the true effect does not fall into their confidence interval, we would need a sample size of 108,218 participants (alpha = 5%, one-tailed test<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> ). Conversely, with the small telescopes approach, we would aim to test whether the replication effect is <em>smaller</em> than the effect which the original study had 33% power to detect, <em>r </em>= -.043 (alpha = 5%, one-tailed test). Simonsohn <span class="citation" data-cites="Simonsohn2015">(<a href="references.html#ref-Simonsohn2015" role="doc-biblioref">2015</a>)</span> showed that this requires a sample 2.5 times as large as the original for 80% power. However, we deem that level of power insufficient for replications, and instead suggest aiming for 95% power (given that a false negative in a replication leads to a wrong claim regarding the absence <em>of an effect</em>). This requires a multiple of 4.5 <span class="citation" data-cites="Wallrich2025">(rather than 2.5, see <a href="references.html#ref-Wallrich2025" role="doc-biblioref">Wallrich, 2025</a>)</span>, so a sample is in this case of 4.5 * 793 = 3,569 participants. If this replication then results in an estimate that is <em>significantly smaller </em>than the effect the original study had 33% power to detect, the small telescopes approach would suggest treating the original study as unable to provide reliable evidence for its claim.</p>
</section>
<section id="equivalence-testing" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="equivalence-testing"><span class="header-section-number">6.2.2</span> Equivalence Testing</h3>
<p>If statements can be made about the smallest effect size of interest (SESOI), researchers can aim to test whether the replication effect is smaller than that. Given that the direction is fixed by the original, this simply requires running a one-sided test, e.g., a <em>t</em>-test in the case of a two group design, in the “lesser” direction. If the replication effect size is significantly smaller than the SESOI, the original claim is taken to be refuted in this instance by those who accept that this is really the smallest effect of interest. Lakens et al. <span class="citation" data-cites="LakensEtAl2018">(<a href="references.html#ref-LakensEtAl2018" role="doc-biblioref">2018</a>)</span> provide a practical tutorial on equivalence testing, though they focus on cases where observations in either direction would falsify the null hypothesis.</p>
</section>
<section id="bayesian-approach" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="bayesian-approach"><span class="header-section-number">6.2.3</span> Bayesian Approach</h3>
<p>External knowledge can be incorporated into sample size planning (uninformative / flat priors; heterogeneity; shrinkage) using the R package BayesRepDesign <span class="citation" data-cites="PawelEtAl2023">(<a href="references.html#ref-PawelEtAl2023" role="doc-biblioref">Pawel et al., 2023</a>)</span>. Moreover, Micheloud and Held <span class="citation" data-cites="MicheloudHeld2022">(<a href="references.html#ref-MicheloudHeld2022" role="doc-biblioref">2022</a>)</span> provide a method for incorporating an original study’s uncertainty into power calculations. With interim analyses (e.g., sequential testing) , a replication study can also be stopped early and prevent wasting resources <span class="citation" data-cites="WagenmakersEtAl2019">(<a href="references.html#ref-WagenmakersEtAl2019" role="doc-biblioref">Wagenmakers et al., 2019</a>)</span>. However, when planning to use Bayes Factors to make inferences about replication success, it is important to plan to use plausibly narrow priors. Priors that assign substantial likelihood to effects rarely observed (e.g., N(0,1) priors for standardized mean differences in the social sciences) may be taken to unfairly privilege the null hypothesis, which is inappropriate for a study setting out to find support for it.</p>
</section>
<section id="meta-analytical-estimates" class="level3" data-number="6.2.4">
<h3 data-number="6.2.4" class="anchored" data-anchor-id="meta-analytical-estimates"><span class="header-section-number">6.2.4</span> Meta-Analytical Estimates</h3>
<p>If the replication study is part of a larger research programme, it is possible to include other studies in the estimate of the (minimum) effect size one wishes to detect/rule out. The target study may be part of a multistudy paper with at least one other study that includes an effect size for the hypothesis of interest. Researchers can compare the effect sizes and possibly pool them to get a more precise estimate <span class="citation" data-cites="McShaneBockenholt2017">(for a related Shiny App, see <a href="references.html#ref-McShaneBockenholt2017" role="doc-biblioref">McShane &amp; Böckenholt, 2017</a>)</span>.</p>
<p>Metrics such as average effect sizes, heterogeneity, or the confidence interval width are valuable estimates needed for the replication’s sample size justification. If there is a meta-analysis on the general topic, researchers can also use that to inform sample size planning, but should prioritise estimates that aim to correct for publication bias and other QRPs <span class="citation" data-cites="Nagy_2025">(for an overview see <a href="references.html#ref-Nagy_2025" role="doc-biblioref">Nagy et al., 2025</a>)</span>. They should also choose effect sizes from a set of studies that resembles the planned replication study as closely as possible. For correlational effects, researchers can check <a href="metabus.org">metabus.org</a> <span class="citation" data-cites="BoscoEtAl2017">(<a href="references.html#ref-BoscoEtAl2017" role="doc-biblioref">Bosco et al., 2017</a>)</span> to identify similar studies.</p>
</section>
<section id="multilab-replications" class="level3" data-number="6.2.5">
<h3 data-number="6.2.5" class="anchored" data-anchor-id="multilab-replications"><span class="header-section-number">6.2.5</span> Multilab Replications</h3>
<p>Multilab replications, that is replications that are conducted by different groups of researchers in different locations adhering to the same protocol, allow researchers to investigate heterogeneity of effects and estimate effect sizes with high precision. There are currently no standards for planning sample sizes for multilab replications. Depending on the specific goals, a power analysis needs to account for possible moderator hypotheses and the desired precision of effect size, heterogeneity estimates, or cultural variables. Note that this often requires large sample sizes for any level of the moderator (e.g., culture, profession). Usually, the different labs are required to collect data from a minimum number of participants. Each lab’s study and all analysis scripts should be preregistered to prevent local and global QRPs such as optional stopping or ad hoc exclusions of single labs.</p>
</section>
</section>
<section id="changes-in-the-methods" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="changes-in-the-methods"><span class="header-section-number">6.3</span> Changes in the Methods</h2>
<p>A replication study should closely resemble the original study, in the case of conducting a direct/close replication. However, this is difficult for multiple reasons: First, original studies may not include sufficient detail to allow for a replication <span class="citation" data-cites="AguinisSolarino2019 ErringtonEtAl2021a">(<a href="references.html#ref-AguinisSolarino2019" role="doc-biblioref">Aguinis &amp; Solarino, 2019</a>; <a href="references.html#ref-ErringtonEtAl2021a" role="doc-biblioref">Errington et al., 2021</a>)</span>. Second, scientific progress in the form of new methods and insights and cultural changes might require replication researchers to make changes or additions to their study. Third, obvious errors must be corrected. We elaborate on a number of reasons to deviate from an original study. In the replication report, all deviations should be reported and justified exhaustively.</p>
<ul>
<li><p><span style="text - decoration: underline;">Unspecific original materials:</span> If the original study does not specify a key element that is needed for the replication, replication researchers can reach out to the original study’s authors and ask for the details. If this is not possible because authors cannot be reached or they are unwilling/unable to share the materials, new materials must be created. In this case, special attention should be paid to the theory, so that the new materials exhibit both face and construct validity.</p></li>
<li><p><span style="text - decoration: underline;">Deprecated materials:</span> If a psychological study about person perception published in the 1980s used celebrities, the examples used may no longer have the same status. For example, Mussweiler et al. <span class="citation" data-cites="MussweilerEtAl2000">(<a href="references.html#ref-MussweilerEtAl2000" role="doc-biblioref">2000</a>)</span> used “a 10-year old car (1987 Opel Kadett E)” to be evaluated in German Marks. For a new study, car and currency would have to be replaced as a car’s age is strongly associated with price. Like most studies, the original provides no details about the conditions that a new stimulus would have to meet. Ideally, the theoretical requirements for stimuli should be specified in primary research, where they are not, replication authors need to make their own assumptions and report them explicitly <span class="citation" data-cites="SimonsEtAl2017">(see <a href="references.html#ref-SimonsEtAl2017" role="doc-biblioref">Simons et al., 2017</a>)</span>.</p></li>
<li><p><span style="text - decoration: underline;">Translation:</span> Most published original studies are in English. If the replication sample’s mother tongue is not English, translation may be necessary. Standards for translation differ strongly even between subfields. For example, when a personality scale is translated, the translated version will usually be validated and tests of invariance will be required. In social psychology, such procedures are less common, and often merely a back-translation is conducted. However, in any field, measurement invariance is required if one wants to compare effect sizes across samples, so that this should be tested rather than assumed where possible.</p></li>
<li><p><span style="text - decoration: underline;">Necessity of a special sample:</span> Many large-scale replication projects made use of click workers (e.g., via MTurk) or use student samples. Replicators should consider if using such samples satisfy their needs and evaluate which platform to use (for best practices and ethical considerations, see <span class="citation" data-cites="KapitanyKavanagh2023">Kapitány &amp; Kavanagh (<a href="references.html#ref-KapitanyKavanagh2023" role="doc-biblioref">2023</a>)</span>. Even if the original study used such a convenience population, changing to a different convenience population may require tweaks to maintain comparability, e.g.&nbsp;with regard to participant attentiveness and engagement with the paradigm.</p></li>
<li><p><span style="text - decoration: underline;">Quality of methods and apparatus:</span> Replicating old studies often faces the problem that something new has been discovered that should be taken into account. If a specific tool or method is used, there may be another recent method that is more reliable. For example, software for eye tracking studies from the early 2000s is now deprecated; there is new hardware and software that researchers will use. This might also apply to analysis methods, yet where possible, both the results from the original methods as well as state-of-the-art methods should be reported; where a choice has to be made, it is essential that invalid methods are avoided while comparability is maintained as far as possible. Finally, if the original finding’s generalizability is tested, new items or tasks that vary more or less systematically can be added to compare results for the original parts versus these extensions (though order effects have to be carefully considered, as a second manipulation might affect participants differently from a first manipulation)</p></li>
<li><p><span style="text - decoration: underline;">Adding checks:</span> Doing a replication often implies some uncertainty in the results, so it is wise to include checks that will be helpful to interpret the results, especially if they are negative. For example, if there are occurrences that would make the results meaningless, it is good to have a way to measure them and incorporate that into the study. This could include positive or negative controls (items that are diagnostic of the method rather than the question of interest), manipulation checks (generally placed <em>after </em>the critical parts of the experiment), or attention checks. See Frank et al.&nbsp;(2025, <a href="https://experimentology.io/012-collection.html#ensuring-high-quality-data">chapter 12.3</a>) for further discussion.</p></li>
</ul>
</section>
<section id="piloting" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="piloting"><span class="header-section-number">6.4</span> Piloting</h2>
<p>If considerable resources are linked to the full execution of a replication (e.g., in a Registered Replication Report), or when new materials are used, researchers may want to consider piloting it (or parts of it) first. For multi-lab replications, researchers may want to consider a sequential study order in contrast to a simultaneous design: As Buttliere <span class="citation" data-cites="Buttliere2024">(<a href="references.html#ref-Buttliere2024" role="doc-biblioref">2024</a>)</span> put it: “Who gets better results, 39 people doing it the first time or one person doing it 39 times?” (p.4) Beware that piloting may not be of value if it is simply an under-powered version of the study; instead it may be used to identify flaws in the methodology or test assumptions about the distribution of values or participants’ qualitative responses. Importantly, small pilot studies should never be used to derive effect sizes for power analyses as their results are too imprecise.</p>
<p>For instance, researchers should follow general best practices for their replications including piloting their study on a few participants to ensure that the instructions are clear, that the procedure works smoothly (e.g., website loads appropriately), and that all necessary data are recorded. A debriefing survey where pilot participants are asked about their experience, the clarity of instructions, and the clarity of any user interface, can help to identify some issues that could undermine the replication. See Frank et al.&nbsp;(2025, chapter 12.3.1) for further discussion on piloting studies.</p>
<section id="collaborating-and-consulting-with-the-original-authors" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="collaborating-and-consulting-with-the-original-authors"><span class="header-section-number">6.4.1</span> Collaborating and Consulting with the Original Authors</h3>
<p>To reduce the chance that a failure to replicate is dismissed by the original study’s authors afterwards by pointing out a flaw in the method, researchers can consult with the original authors before running the study. However, in the past, this still has not kept the original authors from dismissing a replication as an inadequate test of a hypothesis <span class="citation" data-cites="BaumeisterVohs2016">(<a href="references.html#ref-BaumeisterVohs2016" role="doc-biblioref">Baumeister &amp; Vohs, 2016</a>)</span>. Note that replication researchers have even been accused of “null hacking” <span class="citation" data-cites="Protzko2018">(<a href="references.html#ref-Protzko2018" role="doc-biblioref">Protzko, 2018</a>)</span> although little evidence exists for this claim <span class="citation" data-cites="BerinskyEtAl2021">(<a href="references.html#ref-BerinskyEtAl2021" role="doc-biblioref">Berinsky et al., 2021</a>)</span>. While involving original authors can help in creating a good study when reporting is poor, ideally original studies should be reported in sufficient detail for others to replicate them without further involving the original authors. Historically, the relationship between involvement of original authors and the average replication effect size is not clear (although there have been lab effects in some cases <span class="citation" data-cites="PowersEtAl2013">(<a href="references.html#ref-PowersEtAl2013" role="doc-biblioref">Powers et al., 2013</a>)</span>. This is showcased here in a few examples:</p>
<ul>
<li><p>Powers et al. <span class="citation" data-cites="PowersEtAl2013">(<a href="references.html#ref-PowersEtAl2013" role="doc-biblioref">2013</a>)</span> investigated the effect of video games on information processing and found larger effect sizes for active research groups.</p></li>
<li><p>Ten effects from Open Science Collaboration <span class="citation" data-cites="OpenScienceCollab2015">(<a href="references.html#ref-OpenScienceCollab2015" role="doc-biblioref">2015</a>)</span> were replicated in Many Labs 5 <span class="citation" data-cites="EbersoleEtAl2020">(<a href="references.html#ref-EbersoleEtAl2020" role="doc-biblioref">Ebersole et al., 2020</a>)</span>, where the original authors commented on the study protocols of the planned replication before these replications were conducted, and “the revised protocols produced effect sizes similar to those of the RP:P protocols (Δr = .002 or .014, depending on analytic approach).”</p></li>
<li><p>McCarthy et al. <span class="citation" data-cites="McCarthyEtAl2021">(<a href="references.html#ref-McCarthyEtAl2021" role="doc-biblioref">2021</a>)</span> conducted a multisite replication of hostile priming where one of the original authors was involved. Each laboratory conducted a close and a conceptual replication and found no difference and recommended that “researchers should not invest more resources into trying to detect a hostile priming effect using methods like those described in Srull and Wyer (1979)”.</p></li>
<li><p>After Baumeister and Vohs <span class="citation" data-cites="BaumeisterVohs2016">(<a href="references.html#ref-BaumeisterVohs2016" role="doc-biblioref">2016</a>)</span> criticized the failed registered replication report by Hagger et al. <span class="citation" data-cites="HaggerEtAl2016">(<a href="references.html#ref-HaggerEtAl2016" role="doc-biblioref">2016</a>)</span> for their methods, Vohs et al. <span class="citation" data-cites="VohsEtAl2021">(<a href="references.html#ref-VohsEtAl2021" role="doc-biblioref">2021</a>)</span> conducted another registered replication report and also found a null effect.</p></li>
<li><p>After no effect of the pen-in-mouth task was found in the facial feedback Registered Replication Report by Wagenmakers et al. <span class="citation" data-cites="WagenmakersEtAl2016">(<a href="references.html#ref-WagenmakersEtAl2016" role="doc-biblioref">2016</a>)</span>, another multilab test, which included one of the original authors, arrived at the same results <span class="citation" data-cites="ColesEtAl2022">(<a href="references.html#ref-ColesEtAl2022" role="doc-biblioref">2022</a>)</span>.</p></li>
<li><p>The Many Labs 4 project set out to test the effect of author involvement on replication success but found an overall null effect for the group of studies that did and that did not include original findings’ authors <span class="citation" data-cites="KleinEtAl2014">(<a href="references.html#ref-KleinEtAl2014" role="doc-biblioref">Klein et al., 2014</a>)</span>.</p></li>
<li><p>For social priming studies’ replication success, “the strongest predictor of replication success was whether or not the replication team included at least one of the authors of the original paper” <span class="citation" data-cites="MacGiollaEtAl2024">(<a href="references.html#ref-MacGiollaEtAl2024" role="doc-biblioref">Mac Giolla et al., 2024</a>)</span>.</p></li>
</ul>
</section>
</section>
<section id="adversarial-collaborations" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="adversarial-collaborations"><span class="header-section-number">6.5</span> Adversarial Collaborations</h2>
<p>Although they are not specific to replication projects, researchers have often issued calls for adversarial collaborations <span class="citation" data-cites="ClarkEtAl2022 CowanEtAl2020 CorcoranEtAl2023">(<a href="references.html#ref-ClarkEtAl2022" role="doc-biblioref">Clark et al., 2022</a>; <a href="references.html#ref-CorcoranEtAl2023" role="doc-biblioref">Corcoran et al., 2023</a>; <a href="references.html#ref-CowanEtAl2020" role="doc-biblioref">Cowan et al., 2020</a>)</span>. Thereby, groups of researchers can collaborate and try to settle conflicting views by designing and conducting a study designed to settle a debate. A related idea are “red teams” where experts are invited to critique the analysis plan, without becoming authors and thus without a conflict of interest in terms of desired results <span class="citation" data-cites="LakensEtAl2018">(<a href="references.html#ref-LakensEtAl2018" role="doc-biblioref">2018</a>)</span>.</p>
</section>
<section id="analysis" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="analysis"><span class="header-section-number">6.6</span> Analysis</h2>
<p>Analyses of replication results are often a compromise or a combination of the original analysis and the current state-of-the-art. Generally, replication studies should follow the original analysis plan as closely as possible. That does not only concern statistical procedures but also data processing (e.g., exclusion of outliers, transformation and computation of variables). Even when following the original analysis plan for their confirmatory analysis, researchers should still follow best practices and examine their raw data to check for distributional anomalies to detect whether participants might be inattentive, guessing or speeding, and report relevant sensitivity checks where helpful. Some things to check for include theory-agnostic condition/manipulation checks (e.g., were participants faster in the condition focused on speed?) and the results of attention checks or control trials. Generally, it is advisable not to remove participants from the main analysis on that basis, but instead to confirm that the rates of non-compliance are acceptably low and to report robustness to the exclusion of these participants. See Ward and Meade <span class="citation" data-cites="WardEtAl2023">(<a href="references.html#ref-WardEtAl2023" role="doc-biblioref">2023</a>)</span> for a comprehensive review of strategies for assessing and responding to careless responding.</p>
<p>At times, methodological advances may suggest that the original statistical tests are not robust. In such cases, researchers may want to run both the test that the original study used, as well as the statistical approach that is most appropriate by today’s standards (for instance, both the <em>t</em>-test that can be compared with the original, and the mixed-effect model that is justified by the study design). Where original data is available, or can be obtained from the original authors, researchers might be able to also update the analyses in the original study, which facilitates interpretation.</p>
<p>Where original statistical analyses are fundamentally flawed, replication researchers are faced with a difficult choice. For instance, it has been convincingly demonstrated that the famous Dunning-Kruger effect <span class="citation" data-cites="KrugerEtAl1999">(<a href="references.html#ref-KrugerEtAl1999" role="doc-biblioref">Kruger &amp; Dunning, 1999</a>)</span> is based on analyses strongly influenced by a statistical artifact, namely regression to the mean <span class="citation" data-cites="GignacEtAl2020">(<a href="references.html#ref-GignacEtAl2020" role="doc-biblioref">Gignac &amp; Zajenkowski, 2020</a>)</span>. In such a context, one may want to report results based on the original methods alongside more robust tests, yet needs to be very careful to frame them in a way that “replication success” cannot be claimed in the absence of evidence for the original claim.</p>
<p>Exclusion criteria are another area where there may be tension between the original study and current best practices. Typically, it makes sense to run the analysis both ways to check for robustness, yet one analysis choice should be preregistered as the central analysis.</p>
<p>Naturally, original and replication results should be compared. Unstandardized values can be informative with respect to sample characteristics (e.g., overall reaction times). How to do this analytically depends on the choice of success criteria discussed in the next section.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-AguinisSolarino2019" class="csl-entry" role="listitem">
Aguinis, H., &amp; Solarino, A. M. (2019). Transparency and replicability in qualitative research: The case of interviews with elite informants. <em>Strategic Management Journal</em>, <em>40</em>(8), 1291–1315. <a href="https://doi.org/10.1002/smj.3015">https://doi.org/10.1002/smj.3015</a>
</div>
<div id="ref-BaumeisterVohs2016" class="csl-entry" role="listitem">
Baumeister, R. F., &amp; Vohs, K. D. (2016). Misguided effort with elusive implications. <em>Perspectives on Psychological Science</em>, <em>11</em>(4), 574–575. <a href="https://doi.org/10.1177/1745691616652878">https://doi.org/10.1177/1745691616652878</a>
</div>
<div id="ref-BerinskyEtAl2021" class="csl-entry" role="listitem">
Berinsky, A. J., Druckman, J. N., &amp; Yamamoto, T. (2021). Publication biases in replication studies. <em>Political Analysis</em>, <em>29</em>(3), 370–384. <a href="https://doi.org/10.1017/pan.2020.34">https://doi.org/10.1017/pan.2020.34</a>
</div>
<div id="ref-BoscoEtAl2017" class="csl-entry" role="listitem">
Bosco, F. A., Uggerslev, K. L., &amp; Steel, P. (2017). MetaBUS as a vehicle for facilitating meta-analysis. <em>Human Resource Management Review</em>, <em>27</em>(1), 237–254. <a href="https://doi.org/10.1016/j.hrmr.2016.09.013">https://doi.org/10.1016/j.hrmr.2016.09.013</a>
</div>
<div id="ref-BoyceEtAl2024" class="csl-entry" role="listitem">
Boyce, V., Prystawski, B., Abutto, A. B., Chen, E. M., Chen, Z., Chiu, H., &amp; Frank, M. C. (2024). <em>Estimating the replicability of psychology experiments after an initial failure to replicate</em>. <a href="https://doi.org/10.31234/osf.io/an3yb">https://doi.org/10.31234/osf.io/an3yb</a>
</div>
<div id="ref-BrandtEtAl2014" class="csl-entry" role="listitem">
Brandt, M. J., IJzerman, H., Dijksterhuis, A., Farach, F. J., Geller, J., Giner-Sorolla, R., &amp; Van’t Veer, A. (2014). The replication recipe: What makes for a convincing replication? <em>Journal of Experimental Social Psychology</em>, <em>50</em>, 217–224. <a href="https://doi.org/10.1016/j.jesp.2013.10.005">https://doi.org/10.1016/j.jesp.2013.10.005</a>
</div>
<div id="ref-BrodeurEtAl2024a" class="csl-entry" role="listitem">
Brodeur, A., Cook, N. M., Hartley, J. S., &amp; Heyes, A. (2024). Do preregistration and preanalysis plans reduce p-hacking and publication bias? Evidence from 15,992 test statistics and suggestions for improvement. <em>Journal of Political Economy Microeconomics</em>, <em>2</em>(3), 527–561. <a href="https://doi.org/10.1086/730455">https://doi.org/10.1086/730455</a>
</div>
<div id="ref-Buttliere2024" class="csl-entry" role="listitem">
Buttliere, B. (2024). <em>Was this registered report pilot tested? Examination of vaidis, sleegers, van leeuwen, DeMarree, ... &amp; priolo, d. (2024)</em>. <a href="https://doi.org/10.31234/osf.io/c6r8x">https://doi.org/10.31234/osf.io/c6r8x</a>
</div>
<div id="ref-ClarkEtAl2022" class="csl-entry" role="listitem">
Clark, C. J., Costello, T., Mitchell, G., &amp; Tetlock, P. E. (2022). Keep your enemies close: Adversarial collaborations will improve behavioral science. <em>Journal of Applied Research in Memory and Cognition</em>, <em>11</em>(1), 1. <a href="https://doi.org/10.1037/mac0000004">https://doi.org/10.1037/mac0000004</a>
</div>
<div id="ref-ColesEtAl2022" class="csl-entry" role="listitem">
Coles, N. A., March, D. S., Marmolejo-Ramos, F., et al. (2022). A multi-lab test of the facial feedback hypothesis by the many smiles collaboration. <em>Nature Human Behaviour</em>, <em>6</em>, 1731–1742. <a href="https://doi.org/10.1038/s41562-022-01458-9">https://doi.org/10.1038/s41562-022-01458-9</a>
</div>
<div id="ref-CorcoranEtAl2023" class="csl-entry" role="listitem">
Corcoran, A. W., Hohwy, J., &amp; Friston, K. J. (2023). Accelerating scientific progress through bayesian adversarial collaboration. <em>Neuron</em>, <em>111</em>(22), 3505–3516. <a href="https://doi.org/10.1016/j.neuron.2023.08.027">https://doi.org/10.1016/j.neuron.2023.08.027</a>
</div>
<div id="ref-CowanEtAl2020" class="csl-entry" role="listitem">
Cowan, N., Belletier, C., Doherty, J. M., Jaroslawska, A. J., Rhodes, S., Forsberg, A., Naveh-Benjamin, M., Barrouillet, P., Camos, V., &amp; Logie, R. H. (2020). How do scientific views change? Notes from an extended adversarial collaboration. <em>Perspectives on Psychological Science</em>, <em>15</em>(4), 1011–1025. <a href="https://doi.org/10.1177/1745691620906415">https://doi.org/10.1177/1745691620906415</a>
</div>
<div id="ref-EbersoleEtAl2020" class="csl-entry" role="listitem">
Ebersole, C. R., Mathur, M. B., Baranski, E., Bart-Plange, D. J., Buttrick, N. R., Chartier, C. R., &amp; Szecsi, P. (2020). Many labs 5: Testing pre-data-collection peer review as an intervention to increase replicability. <em>Advances in Methods and Practices in Psychological Science</em>, <em>3</em>(3), 309–331. <a href="https://doi.org/10.1177/2515245920958687">https://doi.org/10.1177/2515245920958687</a>
</div>
<div id="ref-ErringtonEtAl2021a" class="csl-entry" role="listitem">
Errington, T. M., Denis, A., Perfito, N., Iorns, E., &amp; Nosek, B. A. (2021). Challenges for assessing replicability in preclinical cancer biology. <em>eLife</em>, <em>10</em>, e67995. <a href="https://doi.org/10.7554/eLife.67995">https://doi.org/10.7554/eLife.67995</a>
</div>
<div id="ref-GignacEtAl2020" class="csl-entry" role="listitem">
Gignac, G. E., &amp; Zajenkowski, M. (2020). The dunning-kruger effect is (mostly) a statistical artefact: Valid approaches to testing the hypothesis with individual differences data. <em>Intelligence</em>, <em>80</em>, 101449. <a href="https://doi.org/10.1016/j.intell.2020.101449">https://doi.org/10.1016/j.intell.2020.101449</a>
</div>
<div id="ref-HaggerEtAl2016" class="csl-entry" role="listitem">
Hagger, M. S., Chatzisarantis, N. L. D., Alberts, H., Anggono, C. O., Batailler, C., Birt, A. R., Brand, R., Brandt, M. J., Brewer, G., Bruyneel, S., Calvillo, D. P., Campbell, W. K., Cannon, P. R., Carlucci, M., Carruth, N. P., Cheung, T., Crowell, A., De Ridder, D. T. D., Dewitte, S., &amp; Zwienenberg, M. (2016). A multilab preregistered replication of the ego-depletion effect. <em>Perspectives on Psychological Science</em>, <em>11</em>(4), 546–573. <a href="https://doi.org/10.1177/1745691616652873">https://doi.org/10.1177/1745691616652873</a>
</div>
<div id="ref-KapitanyKavanagh2023" class="csl-entry" role="listitem">
Kapitány, R., &amp; Kavanagh, C. M. (2023). <em>Best practices and ethical considerations for crowd-sourced data in the behavioral sciences</em>. <a href="https://doi.org/10.31219/osf.io/sn5gh">https://doi.org/10.31219/osf.io/sn5gh</a>
</div>
<div id="ref-KleinEtAl2014" class="csl-entry" role="listitem">
Klein, R. A., Ratliff, K. A., Vianello, M., Adams Jr, R. B., Bahník, Š., Bernstein, M. J., &amp; Nosek, B. A. (2014). Investigating variation in replicability. <em>Social Psychology</em>. <a href="https://doi.org/10.1027/1864-9335/a000178">https://doi.org/10.1027/1864-9335/a000178</a>
</div>
<div id="ref-KrugerEtAl1999" class="csl-entry" role="listitem">
Kruger, J., &amp; Dunning, D. (1999). Unskilled and unaware of it: How difficulties in recognizing one’s own incompetence lead to inflated self-assessments. <em>Journal of Personality and Social Psychology</em>, <em>77</em>(6), 1121–1134. <a href="https://doi.org/10.1037/0022-3514.77.6.1121">https://doi.org/10.1037/0022-3514.77.6.1121</a>
</div>
<div id="ref-Lakens2022b" class="csl-entry" role="listitem">
Lakens, D. (2022). Sample size justification. <em>Collabra: Psychology</em>, <em>8</em>(1), 33267. <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a>
</div>
<div id="ref-Lakens2024" class="csl-entry" role="listitem">
Lakens, D. (2024). When and how to deviate from a preregistration. <em>Collabra: Psychology</em>, <em>10</em>(1). <a href="https://doi.org/10.1525/collabra.117094">https://doi.org/10.1525/collabra.117094</a>
</div>
<div id="ref-LakensEtAl2018" class="csl-entry" role="listitem">
Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence testing for psychological research: A tutorial. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(2), 259–269. <a href="https://doi.org/10.1177/2515245918770963">https://doi.org/10.1177/2515245918770963</a>
</div>
<div id="ref-MacGiollaEtAl2024" class="csl-entry" role="listitem">
Mac Giolla, E., Karlsson, S., Neequaye, D. A., &amp; Bergquist, M. (2024). Evaluating the replicability of social priming studies. <em>Meta-Psychology</em>, <em>8</em>. <a href="https://doi.org/10.15626/MP.2022.3308">https://doi.org/10.15626/MP.2022.3308</a>
</div>
<div id="ref-McCarthyEtAl2021" class="csl-entry" role="listitem">
McCarthy, R., Gervais, W., Aczel, B., Al-Kire, R. L., Aveyard, M., Marcella Baraldo, S., &amp; Zogmaister, C. (2021). A multi-site collaborative study of the hostile priming effect. <em>Collabra: Psychology</em>, <em>7</em>(1), 18738. <a href="https://doi.org/10.1525/collabra.18738">https://doi.org/10.1525/collabra.18738</a>
</div>
<div id="ref-McShaneBockenholt2017" class="csl-entry" role="listitem">
McShane, B. B., &amp; Böckenholt, U. (2017). Single-paper meta-analysis: Benefits for study summary, theory testing, and replicability. <em>Journal of Consumer Research</em>, <em>43</em>(6), 1048–1063. <a href="https://doi.org/10.1093/jcr/ucw085">https://doi.org/10.1093/jcr/ucw085</a>
</div>
<div id="ref-MicheloudHeld2022" class="csl-entry" role="listitem">
Micheloud, C., &amp; Held, L. (2022). Power calculations for replication studies. <em>Statistical Science</em>, <em>37</em>(3), 369–379. <a href="https://doi.org/10.1214/21-STS828">https://doi.org/10.1214/21-STS828</a>
</div>
<div id="ref-MussweilerEtAl2000" class="csl-entry" role="listitem">
Mussweiler, T., Strack, F., &amp; Pfeiffer, T. (2000). Overcoming the inevitable anchoring effect: Considering the opposite compensates for selective accessibility. <em>Personality and Social Psychology Bulletin</em>, <em>26</em>(9), 1142–1150. <a href="https://doi.org/10.1177/01461672002611010">https://doi.org/10.1177/01461672002611010</a>
</div>
<div id="ref-Nagy_2025" class="csl-entry" role="listitem">
Nagy, T., Hergert, J., Elsherif, M. M., Wallrich, L., Schmidt, K., Waltzer, T., Payne, J. W., Gjoneska, B., Seetahul, Y., Wang, Y. A., Scharfenberg, D., Tyson, G., Yang, Y.-F., Skvortsova, A., Alarie, S., Graves, K., Sotola, L. K., Moreau, D., &amp; Rubínová, E. (2025). Bestiary of questionable research practices in psychology. <em>Advances in Methods and Practices in Psychological Science</em>, <em>8</em>(3). <a href="https://doi.org/10.1177/25152459251348431">https://doi.org/10.1177/25152459251348431</a>
</div>
<div id="ref-OpenScienceCollab2015" class="csl-entry" role="listitem">
Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. <em>Science</em>, <em>349</em>(6251), aac4716. <a href="https://doi.org/10.1126/science.aac4716">https://doi.org/10.1126/science.aac4716</a>
</div>
<div id="ref-PawelEtAl2023" class="csl-entry" role="listitem">
Pawel, S., Consonni, G., &amp; Held, L. (2023). Bayesian approaches to designing replication studies. <em>Psychological Methods</em>. <a href="https://doi.org/10.1037/met0000604">https://doi.org/10.1037/met0000604</a>
</div>
<div id="ref-PowersEtAl2013" class="csl-entry" role="listitem">
Powers, K. L., Brooks, P. J., Aldrich, N. J., Palladino, M. A., &amp; Alfieri, L. (2013). Effects of video-game play on information processing: A meta-analytic investigation. <em>Psychonomic Bulletin &amp; Review</em>, <em>20</em>(6), 1055–1079. <a href="https://doi.org/10.3758/s13423-013-0418-z">https://doi.org/10.3758/s13423-013-0418-z</a>
</div>
<div id="ref-Protzko2018" class="csl-entry" role="listitem">
Protzko, J. (2018). <em>Null-hacking, a lurking problem</em>. <a href="https://doi.org/10.31234/osf.io/9y3mp">https://doi.org/10.31234/osf.io/9y3mp</a>
</div>
<div id="ref-SchultzeEtAl2018" class="csl-entry" role="listitem">
Schultze, T., Gerlach, T. M., &amp; Rittich, J. C. (2018). Some people heed advice less than others: Agency (but not communion) predicts advice taking. <em>Journal of Behavioral Decision Making</em>, <em>31</em>(3), 430–445. <a href="https://doi.org/10.1002/bdm.2065">https://doi.org/10.1002/bdm.2065</a>
</div>
<div id="ref-SimonsEtAl2017" class="csl-entry" role="listitem">
Simons, D. J., Shoda, Y., &amp; Lindsay, D. S. (2017). Constraints on generality (COG): A proposed addition to all empirical papers. <em>Perspectives on Psychological Science</em>, <em>12</em>(6), 1123–1128. <a href="https://doi.org/10.1177/1745691617708630">https://doi.org/10.1177/1745691617708630</a>
</div>
<div id="ref-Simonsohn2015" class="csl-entry" role="listitem">
Simonsohn, U. (2015). Small telescopes: Detectability and the evaluation of replication results. <em>Psychological Science</em>, <em>26</em>(5), 559–569. <a href="https://doi.org/10.1177/0956797614567341">https://doi.org/10.1177/0956797614567341</a>
</div>
<div id="ref-VohsEtAl2021" class="csl-entry" role="listitem">
Vohs, K. D., Schmeichel, B. J., Lohmann, S., Gronau, Q. F., Finley, A. J., Ainsworth, S. E., Alquist, J. L., Baker, M. D., Brizi, A., Bunyi, A., Butschek, G. J., Campbell, C., Capaldi, J., Cau, C., Chambers, H., Chatzisarantis, N. L. D., Christensen, W. J., Clay, S. L., Curtis, J., &amp; Albarracín, D. (2021). A multisite preregistered paradigmatic test of the ego-depletion effect. <em>Psychological Science</em>, <em>32</em>(10), 1566–1581. <a href="https://doi.org/10.1177/0956797621989733">https://doi.org/10.1177/0956797621989733</a>
</div>
<div id="ref-WagenmakersEtAl2016" class="csl-entry" role="listitem">
Wagenmakers, E.-J., Beek, T., Dijkhoff, L., Gronau, Q. F., Acosta, A., Adams, R. B., Albohn, D. N., Allard, E. S., Benning, S. D., Blouin-Hudon, E.-M., Bulnes, L. C., Caldwell, T. L., Calin-Jageman, R. J., Capaldi, C. A., Carfagno, N. S., Chasten, K. T., Cleeremans, A., Connell, L., DeCicco, J. M., &amp; Zwaan, R. A. (2016). Registered replication report: Strack, martin, &amp; stepper (1988). <em>Perspectives on Psychological Science</em>, <em>11</em>(6), 917–928. <a href="https://doi.org/10.1177/1745691616674458">https://doi.org/10.1177/1745691616674458</a>
</div>
<div id="ref-WagenmakersEtAl2019" class="csl-entry" role="listitem">
Wagenmakers, E.-J., Gronau, Q. F., &amp; Vandekerckhove, J. (2019). <em>Five bayesian intuitions for the stopping rule principle</em>. <a href="https://doi.org/10.31234/osf.io/5ntkd">https://doi.org/10.31234/osf.io/5ntkd</a>
</div>
<div id="ref-Wallrich2025" class="csl-entry" role="listitem">
Wallrich, L. (2025). <em>Small telescopes for higher-power replications</em>. Personal blog. <a href="https://www.lukaswallrich.coffee/blog/small-telescopes-for-higher-power-replications/">https://www.lukaswallrich.coffee/blog/small-telescopes-for-higher-power-replications/</a>
</div>
<div id="ref-WardEtAl2023" class="csl-entry" role="listitem">
Ward, M. K., &amp; Meade, A. W. (2023). Dealing with careless responding in survey data: Prevention, identification, and recommended best practices. <em>Annual Review of Psychology</em>, <em>74</em>(1), 577–596. <a href="https://doi.org/10.1146/annurev-psych-040422-045007">https://doi.org/10.1146/annurev-psych-040422-045007</a>
</div>
<div id="ref-WillrothAtherton2024" class="csl-entry" role="listitem">
Willroth, E. C., &amp; Atherton, O. E. (2024). Best laid plans: A guide to reporting preregistration deviations. <em>Advances in Methods and Practices in Psychological Science</em>, <em>7</em>(1), 25152459231213802. <a href="https://doi.org/10.1177/25152459231213802">https://doi.org/10.1177/25152459231213802</a>
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that a two-tailed test could be applied as well. Given that the original study has a clear effect and direction, one-tailed gives the original authors the benefit of the doubt.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./execution_reproductions.html" class="pagination-link" aria-label="Execution of Reproductions">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Execution of Reproductions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./discussion.html" class="pagination-link" aria-label="Discussion">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Röseler, L.*, Wallrich, L.*, Hartmann, H., Hüffmeier, J., Goltermann, J., Pennington, C. R., Boyce, V., Field, S. M., Pittelkow, M.-M., Silverstein, P., van Ravenzwaaij, D., Azevedo, F. (2025). Handbook for Reproduction and Replication Studies. Retrieved from https://forrt.org/replication_guide. https://doi.org/10.5281/zenodo.16990115 *shared first authorship</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>